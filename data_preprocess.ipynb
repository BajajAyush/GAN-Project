{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10013423,"sourceType":"datasetVersion","datasetId":6164905}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-26T19:18:39.992274Z","iopub.execute_input":"2024-11-26T19:18:39.992744Z","iopub.status.idle":"2024-11-26T19:18:40.235778Z","shell.execute_reply.started":"2024-11-26T19:18:39.992691Z","shell.execute_reply":"2024-11-26T19:18:40.233173Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlibraries\u001b[49m \n","\u001b[0;31mNameError\u001b[0m: name 'libraries' is not defined"],"ename":"NameError","evalue":"name 'libraries' is not defined","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"!pip install spleeter torch librosa tqdm pyworld","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T17:24:44.982763Z","iopub.execute_input":"2024-11-26T17:24:44.983215Z","iopub.status.idle":"2024-11-26T17:26:36.442591Z","shell.execute_reply.started":"2024-11-26T17:24:44.983188Z","shell.execute_reply":"2024-11-26T17:26:36.441423Z"}},"outputs":[{"name":"stdout","text":"Collecting spleeter\n  Downloading spleeter-2.4.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (0.10.2.post1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.4)\nCollecting pyworld\n  Downloading pyworld-0.3.4.tar.gz (251 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hCollecting ffmpeg-python<0.3.0,>=0.2.0 (from spleeter)\n  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nCollecting httpx<0.20.0,>=0.19.0 (from httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading httpx-0.19.0-py3-none-any.whl.metadata (45 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting norbert<0.3.0,>=0.2.1 (from spleeter)\n  Downloading norbert-0.2.1-py2.py3-none-any.whl.metadata (3.8 kB)\nCollecting pandas<2.0.0,>=1.3.0 (from spleeter)\n  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting tensorflow<2.10.0,>=2.5.0 (from spleeter)\n  Downloading tensorflow-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\nCollecting typer<0.4.0,>=0.3.2 (from spleeter)\n  Downloading typer-0.3.2-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa) (3.0.1)\nRequirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.26.4)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.14.1)\nRequirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.2.2)\nRequirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.4.2)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (5.1.1)\nRequirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.60.0)\nRequirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.12.1)\nRequirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.8.2)\nRequirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.5.0.post1)\nRequirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa) (0.4)\nRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa) (1.0.8)\nRequirement already satisfied: cython>=0.24 in /opt/conda/lib/python3.10/site-packages (from pyworld) (3.0.10)\nRequirement already satisfied: future in /opt/conda/lib/python3.10/site-packages (from ffmpeg-python<0.3.0,>=0.2.0->spleeter) (1.0.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2024.8.30)\nRequirement already satisfied: charset-normalizer in /opt/conda/lib/python3.10/site-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.3.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.3.1)\nCollecting rfc3986<2,>=1.3 (from rfc3986[idna2008]<2,>=1.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\nCollecting httpcore<0.14.0,>=0.13.3 (from httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading httpcore-0.13.7-py3-none-any.whl.metadata (13 kB)\nCollecting h2<5,>=3 (from httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from lazy-loader>=0.1->librosa) (21.3)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa) (0.43.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0,>=1.3.0->spleeter) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<2.0.0,>=1.3.0->spleeter) (2024.1)\nRequirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (3.11.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa) (2.32.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\nRequirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.6.3)\nCollecting flatbuffers<2,>=1.12 (from tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\nCollecting gast<=0.4.0,>=0.2.1 (from tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.62.2)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (3.11.0)\nCollecting keras<2.10.0,>=2.9.0rc0 (from tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nCollecting keras-preprocessing>=1.1.1 (from tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (3.3.0)\nCollecting protobuf<3.20,>=3.9.2 (from tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (70.0.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.16.0)\nCollecting tensorboard<2.10,>=2.9 (from tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (0.37.0)\nCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (2.4.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.10.0,>=2.5.0->spleeter) (1.16.0)\nCollecting click<7.2.0,>=7.1.1 (from typer<0.4.0,>=0.3.2->spleeter)\n  Downloading click-7.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<2.10.0,>=2.5.0->spleeter) (0.43.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\nCollecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\nCollecting h11<0.13,>=0.11 (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading h11-0.12.0-py3-none-any.whl.metadata (8.1 kB)\nCollecting anyio==3.* (from httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter)\n  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (3.7)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx<0.20.0,>=0.19.0->httpx[http2]<0.20.0,>=0.19.0->spleeter) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->lazy-loader>=0.1->librosa) (3.1.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (1.26.18)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (2.30.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (3.6)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (3.0.4)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (2.0.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (0.6.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<2.10.0,>=2.5.0->spleeter) (3.2.2)\nDownloading spleeter-2.4.0-py3-none-any.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\nDownloading httpx-0.19.0-py3-none-any.whl (77 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\nDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorflow-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading typer-0.3.2-py3-none-any.whl (21 kB)\nDownloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\nDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nDownloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading h11-0.12.0-py3-none-any.whl (54 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\nDownloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pyworld\n  Building wheel for pyworld (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyworld: filename=pyworld-0.3.4-cp310-cp310-linux_x86_64.whl size=202492 sha256=a937db6421b49a3315a973d0da6834a7ad9490ea543367edc4184dc3999319b5\n  Stored in directory: /root/.cache/pip/wheels/66/09/8a/a1d79b73d59756f66e9bfe55a199840efc7473adb76ddacdfd\nSuccessfully built pyworld\nInstalling collected packages: tensorboard-plugin-wit, rfc3986, keras, flatbuffers, tensorflow-estimator, tensorboard-data-server, pyworld, protobuf, keras-preprocessing, hyperframe, hpack, h11, gast, ffmpeg-python, click, anyio, typer, pandas, norbert, httpcore, h2, httpx, google-auth-oauthlib, tensorboard, tensorflow, spleeter\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 24.3.25\n    Uninstalling flatbuffers-24.3.25:\n      Successfully uninstalled flatbuffers-24.3.25\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.15.0\n    Uninstalling tensorflow-estimator-2.15.0:\n      Successfully uninstalled tensorflow-estimator-2.15.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: h11\n    Found existing installation: h11 0.14.0\n    Uninstalling h11-0.14.0:\n      Successfully uninstalled h11-0.14.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.5.4\n    Uninstalling gast-0.5.4:\n      Successfully uninstalled gast-0.5.4\n  Attempting uninstall: click\n    Found existing installation: click 8.1.7\n    Uninstalling click-8.1.7:\n      Successfully uninstalled click-8.1.7\n  Attempting uninstall: anyio\n    Found existing installation: anyio 4.4.0\n    Uninstalling anyio-4.4.0:\n      Successfully uninstalled anyio-4.4.0\n  Attempting uninstall: typer\n    Found existing installation: typer 0.12.3\n    Uninstalling typer-0.12.3:\n      Successfully uninstalled typer-0.12.3\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.2\n    Uninstalling pandas-2.2.2:\n      Successfully uninstalled pandas-2.2.2\n  Attempting uninstall: httpcore\n    Found existing installation: httpcore 1.0.5\n    Uninstalling httpcore-1.0.5:\n      Successfully uninstalled httpcore-1.0.5\n  Attempting uninstall: httpx\n    Found existing installation: httpx 0.27.0\n    Uninstalling httpx-0.27.0:\n      Successfully uninstalled httpx-0.27.0\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.16.1\n    Uninstalling tensorflow-2.16.1:\n      Successfully uninstalled tensorflow-2.16.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.8.3 requires cubinlinker, which is not installed.\ncudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.8.3 requires ptxcompiler, which is not installed.\ncuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbeatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\nbigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\nbigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\ncesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ncudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\ncudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask 2024.9.1 requires click>=8.1, but you have click 7.1.2 which is incompatible.\ndask-cuda 24.8.2 requires click>=8.1, but you have click 7.1.2 which is incompatible.\ndask-cudf 24.8.3 requires pandas<2.2.3dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\ndask-expr 1.1.15 requires pandas>=2, but you have pandas 1.5.3 which is incompatible.\ndataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\ndistributed 2024.7.1 requires click>=8.0, but you have click 7.1.2 which is incompatible.\ndistributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\nfastapi 0.111.0 requires httpx>=0.23.0, but you have httpx 0.19.0 which is incompatible.\nfastapi-cli 0.0.4 requires typer>=0.12.3, but you have typer 0.3.2 which is incompatible.\nfeaturetools 1.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nfiona 1.9.6 requires click~=8.0, but you have click 7.1.2 which is incompatible.\nflask 3.0.3 requires click>=8.1.3, but you have click 7.1.2 which is incompatible.\ngoogle-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-aiplatform 0.6.0a1 requires google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1 which is incompatible.\ngoogle-cloud-datastore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-language 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-spanner 3.47.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\ngoogle-cloud-videointelligence 2.13.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\njupyterlab 4.2.5 requires httpx>=0.25.0, but you have httpx 0.19.0 which is incompatible.\njupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires click<9,>=8.0.0, but you have click 7.1.2 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nlibpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmizani 0.11.4 requires pandas>=2.1.0, but you have pandas 1.5.3 which is incompatible.\nonnx 1.17.0 requires protobuf>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nplotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 1.5.3 which is incompatible.\npyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nrapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\ntensorboardx 2.6.2.2 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-decision-forests 1.9.1 requires tensorflow~=2.16.1, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-serving-api 2.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.19.6 which is incompatible.\ntensorflow-serving-api 2.16.1 requires tensorflow<3,>=2.16.1, but you have tensorflow 2.9.3 which is incompatible.\ntensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.9.3 which is incompatible.\ntf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.9.3 which is incompatible.\ntyper-slim 0.12.5 requires click>=8.0.0, but you have click 7.1.2 which is incompatible.\nwoodwork 0.31.0 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\nxarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\nxarray 2024.9.0 requires pandas>=2.1, but you have pandas 1.5.3 which is incompatible.\nydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed anyio-3.7.1 click-7.1.2 ffmpeg-python-0.2.0 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 h11-0.12.0 h2-4.1.0 hpack-4.0.0 httpcore-0.13.7 httpx-0.19.0 hyperframe-6.0.1 keras-2.9.0 keras-preprocessing-1.1.2 norbert-0.2.1 pandas-1.5.3 protobuf-3.19.6 pyworld-0.3.4 rfc3986-1.5.0 spleeter-2.4.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.3 tensorflow-estimator-2.9.0 typer-0.12.5\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nfrom spleeter.separator import Separator\n\ndef extract_vocals(input_dir, vocal_output_dir):\n    \"\"\"\n    Extract vocals from audio files using Spleeter.\n\n    Args:\n    - input_dir (str): Directory containing full songs.\n    - vocal_output_dir (str): Directory to save isolated vocals.\n\n    Returns:\n    - None\n    \"\"\"\n    os.makedirs(vocal_output_dir, exist_ok=True)\n    audio_files = [f for f in os.listdir(input_dir) if f.endswith('.wav')]\n    separator = Separator('spleeter:2stems')\n\n    for audio_file in audio_files:\n        try:\n            input_path = os.path.join(input_dir, audio_file)\n            output_path = os.path.join(vocal_output_dir, audio_file)\n            # Separate vocals\n            separator.separate_to_file(input_path, vocal_output_dir)\n            print(f\"Vocals extracted: {output_path}\")\n        except Exception as e:\n            print(f\"Error extracting vocals from {audio_file}: {e}\")\n\n\ndef preprocess_audio(vocal_input_dir, mel_output_dir, sample_rate=16000, n_mels=80, frame_length=1024, hop_length=256):\n    \"\"\"\n    Preprocess isolated vocal files for CycleGAN-VC2 by converting them to Mel-spectrograms.\n\n    Args:\n    - vocal_input_dir (str): Directory containing isolated vocals.\n    - mel_output_dir (str): Directory to save Mel-spectrograms.\n    - sample_rate (int): Target sample rate.\n    - n_mels (int): Number of Mel-frequency bands.\n    - frame_length (int): FFT window size.\n    - hop_length (int): Hop size for FFT.\n\n    Returns:\n    - None\n    \"\"\"\n    os.makedirs(mel_output_dir, exist_ok=True)\n    vocal_files = [f for f in os.listdir(vocal_input_dir) if f.endswith('.wav')]\n\n    for vocal_file in vocal_files:\n        try:\n            input_path = os.path.join(vocal_input_dir, vocal_file)\n            # Load the audio\n            audio, _ = librosa.load(input_path, sr=sample_rate, mono=True)\n            # Normalize the audio\n            audio = audio / np.max(np.abs(audio))\n            # Extract Mel-spectrogram\n            mel_spec = librosa.feature.melspectrogram(\n                y=audio,\n                sr=sample_rate,\n                n_fft=frame_length,\n                hop_length=hop_length,\n                n_mels=n_mels,\n                power=2.0\n            )\n            # Convert to log scale (dB)\n            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n            # Save Mel-spectrogram\n            output_path = os.path.join(mel_output_dir, f\"{os.path.splitext(vocal_file)[0]}.npy\")\n            np.save(output_path, mel_spec_db)\n            print(f\"Mel-spectrogram saved: {output_path}\")\n        except Exception as e:\n            print(f\"Error processing {vocal_file}: {e}\")\n\n\ndef main():\n    # Paths\n    input_dir = '/kaggle/input/gan-audio/kishore_songs/kishore_songs'  # Replace with the directory containing full songs\n    vocal_output_dir = '/kaggle/working/SongData/kishore_songs/vocals/'  # Directory to save isolated vocals\n    mel_output_dir = '/kaggle/working/SongData/kishore_songs/spec'  # Directory to save Mel-spectrograms\n\n    # Step 1: Extract vocals\n    print(\"Extracting vocals...\")\n    extract_vocals(input_dir, vocal_output_dir)\n\n    # Step 2: Preprocess vocals to generate Mel-spectrograms\n    #print(\"Generating Mel-spectrograms...\")\n    #preprocess_audio(vocal_output_dir, mel_output_dir)\n\n    input_dir = '/kaggle/input/gan-audio/arijit_songs/arijit_songs'  # Replace with the directory containing full songs\n    vocal_output_dir = '/kaggle/working/SongData/arijit_songs/vocals/'  # Directory to save isolated vocals\n    mel_output_dir = '/kaggle/working/SongData/arijit_songs/spec'  # Directory to save Mel-spectrograms\n\n    # Step 1: Extract vocals\n    print(\"Extracting vocals...\")\n    extract_vocals(input_dir, vocal_output_dir)\n\n    # Step 2: Preprocess vocals to generate Mel-spectrograms\n    #print(\"Generating Mel-spectrograms...\")\n    #preprocess_audio(vocal_output_dir, mel_output_dir)\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T17:27:10.777276Z","iopub.status.idle":"2024-11-26T17:27:10.777768Z","shell.execute_reply.started":"2024-11-26T17:27:10.777509Z","shell.execute_reply":"2024-11-26T17:27:10.777554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\n\ndef preprocess_audio_recursive(root_dir, mel_output_dir, sample_rate=16000, n_mels=80, frame_length=1024, hop_length=256):\n    \"\"\"\n    Preprocess all `.wav` files in subfolders by converting them to Mel-spectrograms.\n\n    Args:\n    - root_dir (str): Root directory containing subfolders with `.wav` files.\n    - mel_output_dir (str): Directory to save Mel-spectrogram `.npy` files.\n    - sample_rate (int): Target sample rate for the audio files.\n    - n_mels (int): Number of Mel-frequency bands.\n    - frame_length (int): FFT window size.\n    - hop_length (int): Hop size for FFT.\n\n    Returns:\n    - None\n    \"\"\"\n    os.makedirs(mel_output_dir, exist_ok=True)\n\n    for subdir, _, files in os.walk(root_dir):\n        for file in files:\n            if file.endswith('.wav'):\n                try:\n                    input_path = os.path.join(subdir, file)\n                    \n                    # Load the isolated vocal audio\n                    audio, _ = librosa.load(input_path, sr=sample_rate, mono=True)\n                    \n                    # Normalize the audio\n                    audio = audio / np.max(np.abs(audio))\n                    \n                    # Extract Mel-spectrogram\n                    mel_spec = librosa.feature.melspectrogram(\n                        y=audio,\n                        sr=sample_rate,\n                        n_fft=frame_length,\n                        hop_length=hop_length,\n                        n_mels=n_mels,\n                        power=2.0\n                    )\n                    \n                    # Convert to log scale (dB)\n                    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n                    \n                    # Create subdirectory structure in the output directory\n                    relative_path = os.path.relpath(subdir, root_dir)\n                    mel_subdir = os.path.join(mel_output_dir, relative_path)\n                    os.makedirs(mel_subdir, exist_ok=True)\n                    \n                    # Save the Mel-spectrogram as a `.npy` file\n                    output_path = os.path.join(mel_subdir, f\"{os.path.splitext(file)[0]}.npy\")\n                    np.save(output_path, mel_spec_db)\n                    print(f\"Processed and saved Mel-spectrogram: {output_path}\")\n\n                except Exception as e:\n                    print(f\"Error processing {file} in {subdir}: {e}\")\n\n# Example usage\nvocal_input_directory = \"/kaggle/working/SongData/arijit_songs/vocals\"  # Replace with your extracted vocals directory\nmel_output_directory = \"/kaggle/working/SongData/arijit_songs/spec\"   # Directory to save Mel-spectrograms\npreprocess_audio_recursive(vocal_input_directory, mel_output_directory)\n\nvocal_input_directory = \"/kaggle/working/SongData/kishore_songs/vocals\"  # Replace with your extracted vocals directory\nmel_output_directory = \"/kaggle/working/SongData/kishore_songs/spec\"   # Directory to save Mel-spectrograms\npreprocess_audio_recursive(vocal_input_directory, mel_output_directory)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\ndef reorganize_vocal_files(root_dir, output_dir):\n    \"\"\"\n    Reorganize vocals.npy files into a new folder structure.\n\n    Args:\n    - root_dir (str): Path to the root directory containing the 'spec' folder.\n    - output_dir (str): Path to the output directory where new 'spec' structure will be created.\n\n    Returns:\n    - None\n    \"\"\"\n    arijit_source_dir = os.path.join(root_dir, \"arijit_songs\", \"spec\")\n    kishore_source_dir = os.path.join(root_dir, \"kishore_songs\", \"spec\")\n    \n    # Define output directories\n    arijit_output_dir = os.path.join(output_dir, \"spec\", \"arijit\")\n    kishore_output_dir = os.path.join(output_dir, \"spec\", \"kishore\")\n    \n    # Create output directories\n    os.makedirs(arijit_output_dir, exist_ok=True)\n    os.makedirs(kishore_output_dir, exist_ok=True)\n    \n    # Function to process a source directory\n    def process_source_dir(source_dir, output_subdir):\n        if not os.path.exists(source_dir):\n            print(f\"Source directory {source_dir} does not exist. Skipping.\")\n            return\n        \n        for song_folder in os.listdir(source_dir):\n            song_path = os.path.join(source_dir, song_folder)\n            if os.path.isdir(song_path):  # Ensure it's a folder\n                vocals_file = os.path.join(song_path, \"vocals.npy\")\n                if os.path.exists(vocals_file):\n                    # Rename and move vocals.npy\n                    new_filename = f\"{song_folder}-vocals.npy\"\n                    output_path = os.path.join(output_subdir, new_filename)\n                    shutil.copy(vocals_file, output_path)\n                    print(f\"Copied: {vocals_file} -> {output_path}\")\n                else:\n                    print(f\"vocals.npy not found in {song_path}. Skipping.\")\n    \n    # Process Arijit and Kishore source directories\n    process_source_dir(arijit_source_dir, arijit_output_dir)\n    process_source_dir(kishore_source_dir, kishore_output_dir)\n    print(\"Reorganization complete.\")\n\n# Example usage\nroot_directory = \"/kaggle/working/SongData\"  # Replace with the path to your 'SongData' folder\noutput_directory = \"/kaggle/working/specs\"  # Replace with the path to your desired output location\nreorganize_vocal_files(root_directory, output_directory)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nfrom tqdm import tqdm\n\n# Generator\nclass Generator(nn.Module):\n    def __init__(self, input_dim=80, hidden_dim=256, num_residual_blocks=6):\n        super(Generator, self).__init__()\n        layers = [\n            nn.Conv1d(input_dim, hidden_dim, kernel_size=15, padding=7),\n            nn.InstanceNorm1d(hidden_dim),\n            nn.ReLU(inplace=True)\n        ]\n\n        # Downsampling\n        for _ in range(2):\n            layers.append(\n                nn.Conv1d(hidden_dim, hidden_dim * 2, kernel_size=5, stride=2, padding=2)\n            )\n            layers.append(nn.InstanceNorm1d(hidden_dim * 2))\n            layers.append(nn.ReLU(inplace=True))\n            hidden_dim *= 2\n\n        # Residual blocks\n        for _ in range(num_residual_blocks):\n            layers.append(ResidualBlock(hidden_dim))\n\n        # Upsampling\n        for _ in range(2):\n            layers.append(\n                nn.ConvTranspose1d(hidden_dim, hidden_dim // 2, kernel_size=5, stride=2, padding=2, output_padding=1)\n            )\n            layers.append(nn.InstanceNorm1d(hidden_dim // 2))\n            layers.append(nn.ReLU(inplace=True))\n            hidden_dim //= 2\n\n        layers.append(nn.Conv1d(hidden_dim, input_dim, kernel_size=15, padding=7))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, dim):\n        super(ResidualBlock, self).__init__()\n        self.block = nn.Sequential(\n            nn.Conv1d(dim, dim, kernel_size=3, padding=1),\n            nn.InstanceNorm1d(dim),\n            nn.ReLU(inplace=True),\n            nn.Conv1d(dim, dim, kernel_size=3, padding=1),\n            nn.InstanceNorm1d(dim)\n        )\n\n    def forward(self, x):\n        return x + self.block(x)\n\n# Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self, input_dim=80):\n        super(Discriminator, self).__init__()\n        layers = [\n            nn.Conv1d(input_dim, 128, kernel_size=15, stride=1, padding=7),\n            nn.LeakyReLU(0.2, inplace=True),\n        ]\n\n        num_filters = 128\n        for _ in range(3):\n            layers.append(\n                nn.Conv1d(num_filters, num_filters * 2, kernel_size=15, stride=2, padding=7)\n            )\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            num_filters *= 2\n\n        layers.append(nn.Conv1d(num_filters, 1, kernel_size=3, stride=1, padding=1))\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)\n\n# Dataset\nclass SpectrogramDataset(Dataset):\n    def __init__(self, root_dir, min_length=None, max_length=None):\n        self.files = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.endswith('.npy')]\n        \n        # Load and filter spectrograms based on length\n        self.spectrograms = []\n        for file in self.files:\n            try:\n                spec = np.load(file)\n                \n                # Print shape for debugging\n                print(f\"Loaded {file} with shape: {spec.shape}\")\n                \n                # Handle various possible shapes\n                if spec.ndim == 4:\n                    spec = spec.squeeze()\n                \n                # Ensure shape is (80, time_steps)\n                if spec.ndim == 3:\n                    if spec.shape[0] == 1:\n                        spec = spec.squeeze(0)\n                    elif spec.shape[2] == 80:\n                        spec = spec.transpose(0, 2).squeeze(0)\n                elif spec.ndim == 2:\n                    if spec.shape[1] == 80:\n                        spec = spec.T\n                \n                # Verify shape\n                assert spec.shape[0] == 80, f\"Unexpected spectrogram shape for {file}: {spec.shape}\"\n                \n                # Apply length filtering if specified\n                if min_length is not None and spec.shape[1] < min_length:\n                    continue\n                if max_length is not None and spec.shape[1] > max_length:\n                    continue\n                \n                self.spectrograms.append(spec)\n            except Exception as e:\n                print(f\"Error processing file {file}: {e}\")\n\n    def __len__(self):\n        return len(self.spectrograms)\n\n    def __getitem__(self, idx):\n        return self.spectrograms[idx]  # Return NumPy array directly\n\ndef pad_to_max_size(tensor1, tensor2):\n    # Get the maximum size along the time dimension\n    max_size = max(tensor1.shape[2], tensor2.shape[2])\n    \n    # Pad both tensors to the max size\n    tensor1 = torch.nn.functional.pad(tensor1, (0, max_size - tensor1.shape[2]))\n    tensor2 = torch.nn.functional.pad(tensor2, (0, max_size - tensor2.shape[2]))\n    \n    return tensor1, tensor2\n\n# Utility function to pad or trim tensors to a consistent length\ndef pad_or_trim_tensor(tensor, target_length):\n    # Handle 4D tensor from some spectrogram formats\n    if tensor.ndim == 4:\n        # Squeeze out unnecessary dimensions\n        tensor = tensor.squeeze(0)  # Removing the extra dimension\n\n    # If tensor is already a PyTorch tensor, convert to NumPy if needed\n    if isinstance(tensor, torch.Tensor):\n        tensor = tensor.numpy()\n\n    # Ensure tensor is of shape (80, time_steps)\n    if tensor.ndim == 3:\n        # If shape is (1, 80, time_steps) or (1, time_steps, 80)\n        if tensor.shape[0] == 1:\n            tensor = tensor.squeeze(0)  # Removing the first dimension (channel dimension)\n        elif tensor.shape[2] == 80:\n            tensor = tensor.transpose(0, 2).squeeze(0)\n    elif tensor.ndim == 2:\n        # If shape is (time_steps, 80)\n        if tensor.shape[1] == 80:\n            tensor = tensor.T\n\n    # Ensure shape is (80, time_steps)\n    assert tensor.shape[0] == 80, f\"Unexpected tensor shape: {tensor.shape}\"\n\n    current_length = tensor.shape[1]\n\n    if current_length == target_length:\n        return torch.from_numpy(tensor)  # No need to add batch dimension here\n\n    if current_length < target_length:\n        # Pad with zeros\n        pad_size = target_length - current_length\n        padded = np.pad(tensor, ((0, 0), (0, pad_size)), mode='constant')\n        return torch.from_numpy(padded)  # No need to add batch dimension here\n    else:\n        # Trim \n        return torch.from_numpy(tensor[:, :target_length])  # No need to add batch dimension here\n\n\n\n# Loss Functions\nmse_loss = nn.MSELoss()\nl1_loss = nn.L1Loss()\n\n# Training\n# Training\ndef train_cycle_gan(train_A_dir, train_B_dir, output_dir, epochs=50, batch_size=1, lr=0.0002):\n    # Create output directory if it doesn't exist\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Determine common spectrogram length\n    def get_common_length(dataset):\n        lengths = [spec.shape[1] if isinstance(spec, np.ndarray) else spec.shape[1] for spec in dataset.spectrograms]\n        return min(lengths)\n\n    # Load datasets\n    dataset_A = SpectrogramDataset(train_A_dir)\n    dataset_B = SpectrogramDataset(train_B_dir)\n    \n    print(f\"Dataset A: {len(dataset_A)} spectrograms\")\n    print(f\"Dataset B: {len(dataset_B)} spectrograms\")\n    \n    # Debug: print first few spectrogram shapes\n    if dataset_A.spectrograms:\n        print(\"First spectrogram A shape:\", dataset_A.spectrograms[0].shape)\n    if dataset_B.spectrograms:\n        print(\"First spectrogram B shape:\", dataset_B.spectrograms[0].shape)\n    \n    # Find common length\n    common_length = min(get_common_length(dataset_A), get_common_length(dataset_B))\n    print(f\"Common length: {common_length}\")\n    \n    # Create dataloaders with padding/trimming\n    dataloader_A = DataLoader(dataset_A, batch_size=batch_size, shuffle=True, \n                               collate_fn=lambda x: torch.stack([pad_or_trim_tensor(spec, common_length) for spec in x]))\n    dataloader_B = DataLoader(dataset_B, batch_size=batch_size, shuffle=True, \n                               collate_fn=lambda x: torch.stack([pad_or_trim_tensor(spec, common_length) for spec in x]))\n\n    # Rest of the code remains the same...\n\n    # Initialize models\n    G_A2B = Generator()\n    G_B2A = Generator()\n    D_A = Discriminator()\n    D_B = Discriminator()\n\n    # Optimizers\n    opt_G = optim.Adam(list(G_A2B.parameters()) + list(G_B2A.parameters()), lr=lr, betas=(0.5, 0.999))\n    opt_D_A = optim.Adam(D_A.parameters(), lr=lr, betas=(0.5, 0.999))\n    opt_D_B = optim.Adam(D_B.parameters(), lr=lr, betas=(0.5, 0.999))\n\n    # Training loop\n    for epoch in range(epochs):\n        total_loss_G = 0\n        total_loss_D_A = 0\n        total_loss_D_B = 0\n        \n        progress_bar = tqdm(zip(dataloader_A, dataloader_B), total=min(len(dataloader_A), len(dataloader_B)))\n        for real_A, real_B in progress_bar:\n            # Verify tensor shapes\n            assert real_A.shape[1] == 80, f\"real_A has incorrect shape: {real_A.shape}\"\n            assert real_B.shape[1] == 80, f\"real_B has incorrect shape: {real_B.shape}\"\n            assert real_A.shape[2] == real_B.shape[2], f\"Tensor lengths do not match: {real_A.shape}, {real_B.shape}\"\n\n            # Train Generators\n            fake_B = G_A2B(real_A)\n            fake_A = G_B2A(real_B)\n            cycle_A = G_B2A(fake_B)\n            cycle_B = G_A2B(fake_A)\n\n            cycle_A, real_A = pad_to_max_size(cycle_A, real_A)\n            cycle_B, real_B = pad_to_max_size(cycle_B, real_B)\n\n            loss_cycle = l1_loss(cycle_A, real_A) + l1_loss(cycle_B, real_B)\n            loss_identity = l1_loss(G_A2B(real_B), real_B) + l1_loss(G_B2A(real_A), real_A)\n            loss_G_A2B = mse_loss(D_B(fake_B), torch.ones_like(D_B(fake_B)))\n            loss_G_B2A = mse_loss(D_A(fake_A), torch.ones_like(D_A(fake_A)))\n            loss_G = loss_G_A2B + loss_G_B2A + 10 * loss_cycle + 5 * loss_identity\n\n            opt_G.zero_grad()\n            loss_G.backward()\n            opt_G.step()\n\n            # Train Discriminators\n            loss_D_A = (mse_loss(D_A(real_A), torch.ones_like(D_A(real_A))) +\n                        mse_loss(D_A(fake_A.detach()), torch.zeros_like(D_A(fake_A)))) * 0.5\n            loss_D_B = (mse_loss(D_B(real_B), torch.ones_like(D_B(real_B))) +\n                        mse_loss(D_B(fake_B.detach()), torch.zeros_like(D_B(fake_B)))) * 0.5\n\n            opt_D_A.zero_grad()\n            loss_D_A.backward()\n            opt_D_A.step()\n\n            opt_D_B.zero_grad()\n            loss_D_B.backward()\n            opt_D_B.step()\n\n            # Accumulate losses for logging\n            total_loss_G += loss_G.item()\n            total_loss_D_A += loss_D_A.item()\n            total_loss_D_B += loss_D_B.item()\n\n            # Update progress bar\n            progress_bar.set_description(f\"Epoch {epoch + 1}/{epochs}\")\n            progress_bar.set_postfix({\n                'Loss G': loss_G.item(), \n                'Loss D_A': loss_D_A.item(), \n                'Loss D_B': loss_D_B.item()\n            })\n\n        # Print average losses for the epoch\n        print(f\"Epoch {epoch + 1}/{epochs}\")\n        print(f\"Avg Loss G: {total_loss_G / len(progress_bar):.4f}\")\n        print(f\"Avg Loss D_A: {total_loss_D_A / len(progress_bar):.4f}\")\n        print(f\"Avg Loss D_B: {total_loss_D_B / len(progress_bar):.4f}\")\n\n        # Save models\n        torch.save(G_A2B.state_dict(), os.path.join(output_dir, f'G_A2B_epoch_{epoch + 1}.pth'))\n        torch.save(G_B2A.state_dict(), os.path.join(output_dir, f'G_B2A_epoch_{epoch + 1}.pth'))\n        torch.save(D_A.state_dict(), os.path.join(output_dir, f'D_A_epoch_{epoch + 1}.pth'))\n        torch.save(D_B.state_dict(), os.path.join(output_dir, f'D_B_epoch_{epoch + 1}.pth'))\n\n# Paths (modify these to your specific directories)\ntrain_A_dir = \"/kaggle/working/specs/spec/arijit\"\ntrain_B_dir = \"/kaggle/working/specs/spec/kishore\"\noutput_dir = \"/kaggle/working/saved_models\"\n\n# Ensure to replace the paths with your actual directories\ntrain_cycle_gan(train_A_dir, train_B_dir, output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T17:28:15.746881Z","iopub.execute_input":"2024-11-26T17:28:15.747631Z"}},"outputs":[{"name":"stdout","text":"Loaded /kaggle/working/specs/spec/arijit/song34-vocals.npy with shape: (80, 14554)\nLoaded /kaggle/working/specs/spec/arijit/song9-vocals.npy with shape: (80, 13792)\nLoaded /kaggle/working/specs/spec/arijit/song42-vocals.npy with shape: (80, 18577)\nLoaded /kaggle/working/specs/spec/arijit/song6-vocals.npy with shape: (80, 15008)\nLoaded /kaggle/working/specs/spec/arijit/song37-vocals.npy with shape: (80, 17566)\nLoaded /kaggle/working/specs/spec/arijit/song14-vocals.npy with shape: (80, 16190)\nLoaded /kaggle/working/specs/spec/arijit/song45-vocals.npy with shape: (80, 18143)\nLoaded /kaggle/working/specs/spec/arijit/song40-vocals.npy with shape: (80, 18141)\nLoaded /kaggle/working/specs/spec/arijit/song32-vocals.npy with shape: (80, 16598)\nLoaded /kaggle/working/specs/spec/arijit/song20-vocals.npy with shape: (80, 19540)\nLoaded /kaggle/working/specs/spec/arijit/song41-vocals.npy with shape: (80, 18255)\nLoaded /kaggle/working/specs/spec/arijit/song21-vocals.npy with shape: (80, 18324)\nLoaded /kaggle/working/specs/spec/arijit/song29-vocals.npy with shape: (80, 18033)\nLoaded /kaggle/working/specs/spec/arijit/song3-vocals.npy with shape: (80, 15862)\nLoaded /kaggle/working/specs/spec/arijit/song36-vocals.npy with shape: (80, 18200)\nLoaded /kaggle/working/specs/spec/arijit/song22-vocals.npy with shape: (80, 20298)\nLoaded /kaggle/working/specs/spec/arijit/song19-vocals.npy with shape: (80, 24035)\nLoaded /kaggle/working/specs/spec/arijit/song24-vocals.npy with shape: (80, 16771)\nLoaded /kaggle/working/specs/spec/arijit/song4-vocals.npy with shape: (80, 22386)\nLoaded /kaggle/working/specs/spec/arijit/song5-vocals.npy with shape: (80, 15945)\nLoaded /kaggle/working/specs/spec/arijit/song38-vocals.npy with shape: (80, 12920)\nLoaded /kaggle/working/specs/spec/arijit/song25-vocals.npy with shape: (80, 9565)\nLoaded /kaggle/working/specs/spec/arijit/song15-vocals.npy with shape: (80, 20943)\nLoaded /kaggle/working/specs/spec/arijit/song33-vocals.npy with shape: (80, 16841)\nLoaded /kaggle/working/specs/spec/arijit/song12-vocals.npy with shape: (80, 19555)\nLoaded /kaggle/working/specs/spec/arijit/song30-vocals.npy with shape: (80, 19382)\nLoaded /kaggle/working/specs/spec/arijit/song27-vocals.npy with shape: (80, 16464)\nLoaded /kaggle/working/specs/spec/arijit/song13-vocals.npy with shape: (80, 19646)\nLoaded /kaggle/working/specs/spec/arijit/song31-vocals.npy with shape: (80, 11285)\nLoaded /kaggle/working/specs/spec/arijit/song28-vocals.npy with shape: (80, 20071)\nLoaded /kaggle/working/specs/spec/arijit/song10-vocals.npy with shape: (80, 16965)\nLoaded /kaggle/working/specs/spec/arijit/song1-vocals.npy with shape: (80, 11254)\nLoaded /kaggle/working/specs/spec/arijit/song23-vocals.npy with shape: (80, 15625)\nLoaded /kaggle/working/specs/spec/arijit/song39-vocals.npy with shape: (80, 12433)\nLoaded /kaggle/working/specs/spec/arijit/song43-vocals.npy with shape: (80, 16983)\nLoaded /kaggle/working/specs/spec/arijit/song8-vocals.npy with shape: (80, 20061)\nLoaded /kaggle/working/specs/spec/arijit/song44-vocals.npy with shape: (80, 16694)\nLoaded /kaggle/working/specs/spec/arijit/song11-vocals.npy with shape: (80, 17947)\nLoaded /kaggle/working/specs/spec/arijit/song18-vocals.npy with shape: (80, 21010)\nLoaded /kaggle/working/specs/spec/arijit/song17-vocals.npy with shape: (80, 17511)\nLoaded /kaggle/working/specs/spec/arijit/song35-vocals.npy with shape: (80, 18015)\nLoaded /kaggle/working/specs/spec/arijit/song7-vocals.npy with shape: (80, 20388)\nLoaded /kaggle/working/specs/spec/arijit/song2-vocals.npy with shape: (80, 14921)\nLoaded /kaggle/working/specs/spec/arijit/song26-vocals.npy with shape: (80, 20910)\nLoaded /kaggle/working/specs/spec/arijit/song16-vocals.npy with shape: (80, 11472)\nLoaded /kaggle/working/specs/spec/kishore/song34-vocals.npy with shape: (80, 21093)\nLoaded /kaggle/working/specs/spec/kishore/song9-vocals.npy with shape: (80, 13303)\nLoaded /kaggle/working/specs/spec/kishore/song42-vocals.npy with shape: (80, 17873)\nLoaded /kaggle/working/specs/spec/kishore/song84-vocals.npy with shape: (80, 20513)\nLoaded /kaggle/working/specs/spec/kishore/song81-vocals.npy with shape: (80, 18554)\nLoaded /kaggle/working/specs/spec/kishore/song6-vocals.npy with shape: (80, 20582)\nLoaded /kaggle/working/specs/spec/kishore/song37-vocals.npy with shape: (80, 16778)\nLoaded /kaggle/working/specs/spec/kishore/song46-vocals.npy with shape: (80, 17764)\nLoaded /kaggle/working/specs/spec/kishore/song14-vocals.npy with shape: (80, 13485)\nLoaded /kaggle/working/specs/spec/kishore/song75-vocals.npy with shape: (80, 17927)\nLoaded /kaggle/working/specs/spec/kishore/song89-vocals.npy with shape: (80, 13014)\nLoaded /kaggle/working/specs/spec/kishore/song56-vocals.npy with shape: (80, 15279)\nLoaded /kaggle/working/specs/spec/kishore/song45-vocals.npy with shape: (80, 16128)\nLoaded /kaggle/working/specs/spec/kishore/song40-vocals.npy with shape: (80, 17152)\nLoaded /kaggle/working/specs/spec/kishore/song32-vocals.npy with shape: (80, 18585)\nLoaded /kaggle/working/specs/spec/kishore/song20-vocals.npy with shape: (80, 14794)\nLoaded /kaggle/working/specs/spec/kishore/song69-vocals.npy with shape: (80, 16309)\nLoaded /kaggle/working/specs/spec/kishore/song41-vocals.npy with shape: (80, 19615)\nLoaded /kaggle/working/specs/spec/kishore/song55-vocals.npy with shape: (80, 27240)\nLoaded /kaggle/working/specs/spec/kishore/song21-vocals.npy with shape: (80, 17134)\nLoaded /kaggle/working/specs/spec/kishore/song29-vocals.npy with shape: (80, 14156)\nLoaded /kaggle/working/specs/spec/kishore/song3-vocals.npy with shape: (80, 16182)\nLoaded /kaggle/working/specs/spec/kishore/song36-vocals.npy with shape: (80, 22048)\nLoaded /kaggle/working/specs/spec/kishore/song22-vocals.npy with shape: (80, 18007)\nLoaded /kaggle/working/specs/spec/kishore/song19-vocals.npy with shape: (80, 14951)\nLoaded /kaggle/working/specs/spec/kishore/song24-vocals.npy with shape: (80, 14794)\nLoaded /kaggle/working/specs/spec/kishore/song47-vocals.npy with shape: (80, 22432)\nLoaded /kaggle/working/specs/spec/kishore/song4-vocals.npy with shape: (80, 18213)\nLoaded /kaggle/working/specs/spec/kishore/song5-vocals.npy with shape: (80, 12081)\nLoaded /kaggle/working/specs/spec/kishore/song79-vocals.npy with shape: (80, 18049)\nLoaded /kaggle/working/specs/spec/kishore/song83-vocals.npy with shape: (80, 17507)\nLoaded /kaggle/working/specs/spec/kishore/song38-vocals.npy with shape: (80, 20307)\nLoaded /kaggle/working/specs/spec/kishore/song90-vocals.npy with shape: (80, 13202)\nLoaded /kaggle/working/specs/spec/kishore/song82-vocals.npy with shape: (80, 20495)\nLoaded /kaggle/working/specs/spec/kishore/song74-vocals.npy with shape: (80, 11281)\nLoaded /kaggle/working/specs/spec/kishore/song49-vocals.npy with shape: (80, 13703)\nLoaded /kaggle/working/specs/spec/kishore/song68-vocals.npy with shape: (80, 6247)\nLoaded /kaggle/working/specs/spec/kishore/song63-vocals.npy with shape: (80, 19974)\nLoaded /kaggle/working/specs/spec/kishore/song57-vocals.npy with shape: (80, 18758)\nLoaded /kaggle/working/specs/spec/kishore/song67-vocals.npy with shape: (80, 20089)\nLoaded /kaggle/working/specs/spec/kishore/song62-vocals.npy with shape: (80, 13566)\nLoaded /kaggle/working/specs/spec/kishore/song25-vocals.npy with shape: (80, 15169)\nLoaded /kaggle/working/specs/spec/kishore/song15-vocals.npy with shape: (80, 12939)\nLoaded /kaggle/working/specs/spec/kishore/song53-vocals.npy with shape: (80, 16641)\nLoaded /kaggle/working/specs/spec/kishore/song71-vocals.npy with shape: (80, 15023)\nLoaded /kaggle/working/specs/spec/kishore/song33-vocals.npy with shape: (80, 15545)\nLoaded /kaggle/working/specs/spec/kishore/song12-vocals.npy with shape: (80, 13320)\nLoaded /kaggle/working/specs/spec/kishore/song59-vocals.npy with shape: (80, 15326)\nLoaded /kaggle/working/specs/spec/kishore/song76-vocals.npy with shape: (80, 16827)\nLoaded /kaggle/working/specs/spec/kishore/song30-vocals.npy with shape: (80, 25086)\nLoaded /kaggle/working/specs/spec/kishore/song64-vocals.npy with shape: (80, 22143)\nLoaded /kaggle/working/specs/spec/kishore/song27-vocals.npy with shape: (80, 11793)\nLoaded /kaggle/working/specs/spec/kishore/song88-vocals.npy with shape: (80, 13522)\nLoaded /kaggle/working/specs/spec/kishore/song13-vocals.npy with shape: (80, 21125)\nLoaded /kaggle/working/specs/spec/kishore/song31-vocals.npy with shape: (80, 18418)\nLoaded /kaggle/working/specs/spec/kishore/song28-vocals.npy with shape: (80, 17516)\nLoaded /kaggle/working/specs/spec/kishore/song77-vocals.npy with shape: (80, 14481)\nLoaded /kaggle/working/specs/spec/kishore/song54-vocals.npy with shape: (80, 16925)\nLoaded /kaggle/working/specs/spec/kishore/song72-vocals.npy with shape: (80, 16835)\nLoaded /kaggle/working/specs/spec/kishore/song86-vocals.npy with shape: (80, 33343)\nLoaded /kaggle/working/specs/spec/kishore/song10-vocals.npy with shape: (80, 13085)\nLoaded /kaggle/working/specs/spec/kishore/song80-vocals.npy with shape: (80, 17377)\nLoaded /kaggle/working/specs/spec/kishore/song1-vocals.npy with shape: (80, 15429)\nLoaded /kaggle/working/specs/spec/kishore/song51-vocals.npy with shape: (80, 18750)\nLoaded /kaggle/working/specs/spec/kishore/song85-vocals.npy with shape: (80, 17078)\nLoaded /kaggle/working/specs/spec/kishore/song23-vocals.npy with shape: (80, 21824)\nLoaded /kaggle/working/specs/spec/kishore/song60-vocals.npy with shape: (80, 24407)\nLoaded /kaggle/working/specs/spec/kishore/song58-vocals.npy with shape: (80, 21008)\nLoaded /kaggle/working/specs/spec/kishore/song52-vocals.npy with shape: (80, 17124)\nLoaded /kaggle/working/specs/spec/kishore/song39-vocals.npy with shape: (80, 20492)\nLoaded /kaggle/working/specs/spec/kishore/song43-vocals.npy with shape: (80, 17780)\nLoaded /kaggle/working/specs/spec/kishore/song8-vocals.npy with shape: (80, 11037)\nLoaded /kaggle/working/specs/spec/kishore/song61-vocals.npy with shape: (80, 11496)\nLoaded /kaggle/working/specs/spec/kishore/song44-vocals.npy with shape: (80, 16252)\nLoaded /kaggle/working/specs/spec/kishore/song11-vocals.npy with shape: (80, 23837)\nLoaded /kaggle/working/specs/spec/kishore/song78-vocals.npy with shape: (80, 7875)\nLoaded /kaggle/working/specs/spec/kishore/song73-vocals.npy with shape: (80, 16272)\nLoaded /kaggle/working/specs/spec/kishore/song18-vocals.npy with shape: (80, 20192)\nLoaded /kaggle/working/specs/spec/kishore/song65-vocals.npy with shape: (80, 15129)\nLoaded /kaggle/working/specs/spec/kishore/song70-vocals.npy with shape: (80, 22489)\nLoaded /kaggle/working/specs/spec/kishore/song66-vocals.npy with shape: (80, 16575)\nLoaded /kaggle/working/specs/spec/kishore/song17-vocals.npy with shape: (80, 12394)\nLoaded /kaggle/working/specs/spec/kishore/song87-vocals.npy with shape: (80, 26992)\nLoaded /kaggle/working/specs/spec/kishore/song35-vocals.npy with shape: (80, 18773)\nLoaded /kaggle/working/specs/spec/kishore/song50-vocals.npy with shape: (80, 14939)\nLoaded /kaggle/working/specs/spec/kishore/song7-vocals.npy with shape: (80, 23689)\nLoaded /kaggle/working/specs/spec/kishore/song48-vocals.npy with shape: (80, 20229)\nLoaded /kaggle/working/specs/spec/kishore/song2-vocals.npy with shape: (80, 17945)\nLoaded /kaggle/working/specs/spec/kishore/song26-vocals.npy with shape: (80, 15865)\nLoaded /kaggle/working/specs/spec/kishore/song16-vocals.npy with shape: (80, 18711)\nDataset A: 45 spectrograms\nDataset B: 90 spectrograms\nFirst spectrogram A shape: (80, 14554)\nFirst spectrogram B shape: (80, 21093)\nCommon length: 6247\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/200: 100%|██████████| 45/45 [12:57<00:00, 17.29s/it, Loss G=1.26e+3, Loss D_A=0.0527, Loss D_B=0.027]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/200\nAvg Loss G: 1513.5315\nAvg Loss D_A: 56.3634\nAvg Loss D_B: 36.9232\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/200: 100%|██████████| 45/45 [12:40<00:00, 16.91s/it, Loss G=692, Loss D_A=0.0811, Loss D_B=0.0515]    \n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/200\nAvg Loss G: 1036.4327\nAvg Loss D_A: 0.0698\nAvg Loss D_B: 0.0502\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/200: 100%|██████████| 45/45 [12:16<00:00, 16.36s/it, Loss G=558, Loss D_A=0.157, Loss D_B=0.139]  \n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/200\nAvg Loss G: 699.6197\nAvg Loss D_A: 0.3495\nAvg Loss D_B: 0.0711\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/200: 100%|██████████| 45/45 [12:29<00:00, 16.67s/it, Loss G=331, Loss D_A=0.0793, Loss D_B=0.132] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 4/200\nAvg Loss G: 419.4922\nAvg Loss D_A: 0.1060\nAvg Loss D_B: 0.0671\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/200: 100%|██████████| 45/45 [12:23<00:00, 16.53s/it, Loss G=326, Loss D_A=0.105, Loss D_B=0.0877] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 5/200\nAvg Loss G: 329.1983\nAvg Loss D_A: 0.1015\nAvg Loss D_B: 0.0885\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/200: 100%|██████████| 45/45 [12:16<00:00, 16.36s/it, Loss G=311, Loss D_A=0.0584, Loss D_B=0.0824]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6/200\nAvg Loss G: 306.1470\nAvg Loss D_A: 0.0917\nAvg Loss D_B: 0.0837\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/200:  38%|███▊      | 17/45 [04:35<07:36, 16.32s/it, Loss G=267, Loss D_A=0.112, Loss D_B=0.243]  ","output_type":"stream"}],"execution_count":null}]}